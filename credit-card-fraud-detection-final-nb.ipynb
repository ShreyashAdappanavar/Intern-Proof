{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Things to try:</h1>\n",
    "\n",
    "- ANOVA SCORE MODELS\n",
    "\n",
    "- DATASET WITH DIFFERENT KINDS OF OVER AND UNDER SAMPLING STRATEGY ON THE FINAL BEST MODEL WE GET WITH THE CURRENT STRATEGIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:31.730477Z",
     "iopub.status.busy": "2023-04-03T16:43:31.729305Z",
     "iopub.status.idle": "2023-04-03T16:43:31.773980Z",
     "shell.execute_reply": "2023-04-03T16:43:31.772595Z",
     "shell.execute_reply.started": "2023-04-03T16:43:31.730425Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:31.777562Z",
     "iopub.status.busy": "2023-04-03T16:43:31.776661Z",
     "iopub.status.idle": "2023-04-03T16:43:34.078171Z",
     "shell.execute_reply": "2023-04-03T16:43:34.076859Z",
     "shell.execute_reply.started": "2023-04-03T16:43:31.777516Z"
    }
   },
   "outputs": [],
   "source": [
    "## Importing all the required Libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "\n",
    "# Classifier Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import collections\n",
    "\n",
    "# Other Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:34.081681Z",
     "iopub.status.busy": "2023-04-03T16:43:34.080309Z",
     "iopub.status.idle": "2023-04-03T16:43:34.093400Z",
     "shell.execute_reply": "2023-04-03T16:43:34.091431Z",
     "shell.execute_reply.started": "2023-04-03T16:43:34.081622Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Displaying all floating point numbers upto 3 decimal places\n",
    "pd.options.display.float_format = '{:.3f}'.format   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:43.386717Z",
     "iopub.status.busy": "2023-04-03T16:43:43.386296Z",
     "iopub.status.idle": "2023-04-03T16:43:48.833496Z",
     "shell.execute_reply": "2023-04-03T16:43:48.832505Z",
     "shell.execute_reply.started": "2023-04-03T16:43:43.386679Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:48.836087Z",
     "iopub.status.busy": "2023-04-03T16:43:48.835454Z",
     "iopub.status.idle": "2023-04-03T16:43:48.881565Z",
     "shell.execute_reply": "2023-04-03T16:43:48.880132Z",
     "shell.execute_reply.started": "2023-04-03T16:43:48.836048Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:48.883629Z",
     "iopub.status.busy": "2023-04-03T16:43:48.883173Z",
     "iopub.status.idle": "2023-04-03T16:43:48.926171Z",
     "shell.execute_reply": "2023-04-03T16:43:48.924822Z",
     "shell.execute_reply.started": "2023-04-03T16:43:48.883590Z"
    }
   },
   "outputs": [],
   "source": [
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:48.930460Z",
     "iopub.status.busy": "2023-04-03T16:43:48.929923Z",
     "iopub.status.idle": "2023-04-03T16:43:49.440440Z",
     "shell.execute_reply": "2023-04-03T16:43:49.439148Z",
     "shell.execute_reply.started": "2023-04-03T16:43:48.930404Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:49.442509Z",
     "iopub.status.busy": "2023-04-03T16:43:49.442126Z",
     "iopub.status.idle": "2023-04-03T16:43:49.479148Z",
     "shell.execute_reply": "2023-04-03T16:43:49.477956Z",
     "shell.execute_reply.started": "2023-04-03T16:43:49.442468Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> It seems there are no non null values in the dataset. Let's confirm it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:49.481327Z",
     "iopub.status.busy": "2023-04-03T16:43:49.480832Z",
     "iopub.status.idle": "2023-04-03T16:43:49.509419Z",
     "shell.execute_reply": "2023-04-03T16:43:49.508135Z",
     "shell.execute_reply.started": "2023-04-03T16:43:49.481275Z"
    }
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>So there are no non-null values. We also know that all the data has already been scaled (because the numerical variables have undergone PCA transformation, which requires the scaling of inputs). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>More than 75% of the transactions have amount less than 100$!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:49.512498Z",
     "iopub.status.busy": "2023-04-03T16:43:49.511050Z",
     "iopub.status.idle": "2023-04-03T16:43:49.525279Z",
     "shell.execute_reply": "2023-04-03T16:43:49.523814Z",
     "shell.execute_reply.started": "2023-04-03T16:43:49.512443Z"
    }
   },
   "outputs": [],
   "source": [
    "## Checking the distribution of the classes in the dataset\n",
    "df['Class'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:49.528122Z",
     "iopub.status.busy": "2023-04-03T16:43:49.527079Z",
     "iopub.status.idle": "2023-04-03T16:43:49.546460Z",
     "shell.execute_reply": "2023-04-03T16:43:49.544701Z",
     "shell.execute_reply.started": "2023-04-03T16:43:49.528049Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"The percentage of non-fraud transactions are: {}%\".format(df.Class.value_counts()[0]*100/len(df)))\n",
    "print(\"The percentage of fraud transactions are: {}%\".format(df.Class.value_counts()[1]*100/len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>This is an extremely skewed dataset and we will have to perform some steps to handle the highly imbalanced set of classes. Let's plot a Histogram to further visualise the extent of class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:49.548584Z",
     "iopub.status.busy": "2023-04-03T16:43:49.548207Z",
     "iopub.status.idle": "2023-04-03T16:43:49.806936Z",
     "shell.execute_reply": "2023-04-03T16:43:49.805510Z",
     "shell.execute_reply.started": "2023-04-03T16:43:49.548549Z"
    }
   },
   "outputs": [],
   "source": [
    "counts = df[\"Class\"].value_counts()\n",
    "plt.bar(counts.index, counts.values, color = ['g', 'r']) # Green: Non-Fraud, Red: Fraud\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Value Count\")\n",
    "plt.title(\"Fraud v/s Non-Fraud Transactions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Let's have a look at the mean values of all the columns for fraud as well as non fraud transactions:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:49.810053Z",
     "iopub.status.busy": "2023-04-03T16:43:49.809671Z",
     "iopub.status.idle": "2023-04-03T16:43:49.823508Z",
     "shell.execute_reply": "2023-04-03T16:43:49.821949Z",
     "shell.execute_reply.started": "2023-04-03T16:43:49.810018Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"For Fraudulent trnsactions:-\")\n",
    "df[df['Class'] == 1].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:49.825691Z",
     "iopub.status.busy": "2023-04-03T16:43:49.825312Z",
     "iopub.status.idle": "2023-04-03T16:43:49.896471Z",
     "shell.execute_reply": "2023-04-03T16:43:49.894931Z",
     "shell.execute_reply.started": "2023-04-03T16:43:49.825657Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"For Non-Fraudulent trnsactions:-\")\n",
    "df[df['Class'] == 0].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* HUGE variation in the values of V1 - V28 for fraud v/s non fraud transactions. For non-fraudulent transactions, the mean values of the columns are very close to 0. For fraudulent transactions, the mean values differ drastically away from 0.\n",
    "* Mean amount of fraud transaction:- 122.211\n",
    "* Mean amount of non fraud transaction:- 88.291"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T05:28:13.74656Z",
     "iopub.status.busy": "2023-03-05T05:28:13.746101Z",
     "iopub.status.idle": "2023-03-05T05:28:14.299864Z",
     "shell.execute_reply": "2023-03-05T05:28:14.297569Z",
     "shell.execute_reply.started": "2023-03-05T05:28:13.746519Z"
    }
   },
   "source": [
    "<h4> Let's make a correlation heatmap to check the correlation between different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:49.898795Z",
     "iopub.status.busy": "2023-04-03T16:43:49.898393Z",
     "iopub.status.idle": "2023-04-03T16:43:51.139409Z",
     "shell.execute_reply": "2023-04-03T16:43:51.138080Z",
     "shell.execute_reply.started": "2023-04-03T16:43:49.898756Z"
    }
   },
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "sns.heatmap(corr, cmap='RdBu', vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Due to too many properties present, we will plot the correlation with only the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:51.142747Z",
     "iopub.status.busy": "2023-04-03T16:43:51.142326Z",
     "iopub.status.idle": "2023-04-03T16:43:51.994147Z",
     "shell.execute_reply": "2023-04-03T16:43:51.992958Z",
     "shell.execute_reply.started": "2023-04-03T16:43:51.142696Z"
    }
   },
   "outputs": [],
   "source": [
    "colors = ['#FFD700','#3B3B3C']\n",
    "\n",
    "corr = df.corrwith(df['Class']).sort_values(ascending = False).to_frame()\n",
    "corr.columns = ['Correlation']\n",
    "fig,ax = plt.subplots(nrows = 1,ncols = 2,figsize = (5,10))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.heatmap(corr.iloc[:15,:],annot = True,cmap = colors,linewidths = 0.4,linecolor = 'black',cbar = False)\n",
    "plt.title('Part 1')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap(corr.iloc[15:30],annot = True,cmap = colors,linewidths = 0.4,linecolor = 'black',cbar = False)\n",
    "plt.title('Part 2')\n",
    "\n",
    "fig.tight_layout(w_pad = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For feature selection, we will exclude the features having correlation values between [-0.1,0.1].\n",
    "- V4, V11 are positively correlated and V7, V3, V16, V10, V12, V14, V17 are negatively correlated with the Class feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:51.996159Z",
     "iopub.status.busy": "2023-04-03T16:43:51.995675Z",
     "iopub.status.idle": "2023-04-03T16:43:52.146272Z",
     "shell.execute_reply": "2023-04-03T16:43:52.144754Z",
     "shell.execute_reply.started": "2023-04-03T16:43:51.996108Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_series = df.corrwith(df['Class'])\n",
    "corr_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:52.148164Z",
     "iopub.status.busy": "2023-04-03T16:43:52.147811Z",
     "iopub.status.idle": "2023-04-03T16:43:52.160297Z",
     "shell.execute_reply": "2023-04-03T16:43:52.158802Z",
     "shell.execute_reply.started": "2023-04-03T16:43:52.148131Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_series = corr_series[~corr_series.between(-0.1, 0.1)]\n",
    "selected_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:52.162399Z",
     "iopub.status.busy": "2023-04-03T16:43:52.162014Z",
     "iopub.status.idle": "2023-04-03T16:43:52.170287Z",
     "shell.execute_reply": "2023-04-03T16:43:52.169242Z",
     "shell.execute_reply.started": "2023-04-03T16:43:52.162365Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_series.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:52.173168Z",
     "iopub.status.busy": "2023-04-03T16:43:52.172700Z",
     "iopub.status.idle": "2023-04-03T16:43:52.208168Z",
     "shell.execute_reply": "2023-04-03T16:43:52.206788Z",
     "shell.execute_reply.started": "2023-04-03T16:43:52.173129Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df[['V3','V4','V7','V10','V11','V12','V14','V16','V17','Class']].copy(deep = True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:44:11.964238Z",
     "iopub.status.busy": "2023-04-03T16:44:11.963820Z",
     "iopub.status.idle": "2023-04-03T16:44:12.128182Z",
     "shell.execute_reply": "2023-04-03T16:44:12.126830Z",
     "shell.execute_reply.started": "2023-04-03T16:44:11.964201Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4> Let's now resample the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:52.210151Z",
     "iopub.status.busy": "2023-04-03T16:43:52.209766Z",
     "iopub.status.idle": "2023-04-03T16:43:52.216410Z",
     "shell.execute_reply": "2023-04-03T16:43:52.215088Z",
     "shell.execute_reply.started": "2023-04-03T16:43:52.210114Z"
    }
   },
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:52.218789Z",
     "iopub.status.busy": "2023-04-03T16:43:52.218299Z",
     "iopub.status.idle": "2023-04-03T16:43:52.319048Z",
     "shell.execute_reply": "2023-04-03T16:43:52.317664Z",
     "shell.execute_reply.started": "2023-04-03T16:43:52.218712Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data Balancing\n",
    "# Defining the samplers\n",
    "undersampler = RandomUnderSampler(sampling_strategy = 0.1, random_state=42)\n",
    "oversampler = SMOTE(sampling_strategy=0.5, random_state=42)\n",
    "\n",
    "# Separating input data and target values\n",
    "X1 = df1.iloc[:,:9].values  # Input data\n",
    "y1 = df1.iloc[:,9].values   # Target values\n",
    "\n",
    "# Defining a pipeline\n",
    "pipe = Pipeline([('undersampling', undersampler), ('oversampling', oversampler)])\n",
    "\n",
    "# We will now use the .fit_resample() method to first fit the undersampler object to the data so that they can learn what data points to retain etc. and \n",
    "# then we will fit the oversampler object to the data to learn the patterns of the minority class and figure out the strategy of generating synthetic\n",
    "# data points. We will then use the undersampler to transform the data and achieve the 0.1 sampling_strategy and then use the oversampler object to \n",
    "# transform the data to achieve it's sampling strategy.\n",
    "\n",
    "X1, y1 = pipe.fit_resample(X1, y1)\n",
    "\n",
    "\n",
    "# Counting number of values of each class after resampling\n",
    "Counter(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> DATA BALANCE CALCULATION </H2>\n",
    "    \n",
    "**Sampling Strategy = (Samples of Minority class after resampling)/(Samples of Majority class after resampling)**\n",
    "<br>\n",
    "We are first doing undersampling and then doing oversampling\n",
    "\n",
    "<h3>Undersampling:</h3>\n",
    "Undersampling only affects the number of samples of the majority class. Therefore the number of samples of the minority class before and after undersampling remains the same.\n",
    "\n",
    "sampling_strategy = 0.1\n",
    "\n",
    "0.1 = (492)/(No. of Majority Class samples after undersampling)\n",
    "\n",
    "Therefore, after undersampling: \n",
    "- No. of Minority Class Samples = 492\n",
    "- No. of Majority Class Samples = 4920\n",
    "\n",
    "\n",
    "<h3>Oversampling:</h3>\n",
    "Oversampling only affects the number of samples of the minority class. Therefore the number of samples of the majority class before and after undersampling remains the same.\n",
    "\n",
    "sampling_strategy = 0.5\n",
    "\n",
    "0.5 = (No. of Minority Class samples after undersampling)/(4920)\n",
    "\n",
    "Therefore, after undersampling: \n",
    "- No. of Minority Class Samples = 2460\n",
    "- No. of Majority Class Samples = 4920"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>MAIN EVALUATION METRICS:- </H3>\n",
    "\n",
    "- AUPRC Score\n",
    "\n",
    "- Stratified K Fold Cross Validation Score\n",
    "\n",
    "- Recall Score (Percentage of fraudulent transactions detected)\n",
    "    - Even if our precision is low, it's more important for our recall to be high so that we don't classify a fraudulent transaction as non-fraud\n",
    "\n",
    "<H3>ADDITIONAL METRICS:-</H3>\n",
    "\n",
    "- Confusion Matrix\n",
    "\n",
    "- ROC-AUC plot\n",
    "\n",
    "- Model Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:53.035316Z",
     "iopub.status.busy": "2023-04-03T16:43:53.034866Z",
     "iopub.status.idle": "2023-04-03T16:43:53.042633Z",
     "shell.execute_reply": "2023-04-03T16:43:53.041302Z",
     "shell.execute_reply.started": "2023-04-03T16:43:53.035277Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T16:43:53.517499Z",
     "iopub.status.busy": "2023-04-03T16:43:53.517080Z",
     "iopub.status.idle": "2023-04-03T16:43:53.525537Z",
     "shell.execute_reply": "2023-04-03T16:43:53.524248Z",
     "shell.execute_reply.started": "2023-04-03T16:43:53.517458Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size = 0.20, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T15:14:46.138094Z",
     "iopub.status.busy": "2023-04-03T15:14:46.137346Z",
     "iopub.status.idle": "2023-04-03T15:14:46.150095Z",
     "shell.execute_reply": "2023-04-03T15:14:46.148089Z",
     "shell.execute_reply.started": "2023-04-03T15:14:46.138031Z"
    }
   },
   "outputs": [],
   "source": [
    "### In the next code cell, we will be defining a function to evaluate the model. The following functions are\n",
    "### helper functions to plot confusion matrix and the ROC curve that will be used in the model evaluating function\n",
    "\n",
    "def plot_confusion_matrix(y_test, test_preds):\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test,test_preds)\n",
    "    names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    counts = [value for value in cm.flatten()]\n",
    "    percentages = ['{0:.2%}'.format(value) for value in cm.flatten()/np.sum(cm)]\n",
    "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in zip(names,counts,percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cm,annot = labels,cmap = 'Blues',fmt ='')\n",
    "\n",
    "def plot_ROC_Curve(classifier, X_test, y_test):\n",
    "    plot_roc_curve(classifier, X_test, y_test)\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T13:13:43.992714Z",
     "iopub.status.busy": "2023-03-05T13:13:43.991481Z",
     "iopub.status.idle": "2023-03-05T13:13:44.006362Z",
     "shell.execute_reply": "2023-03-05T13:13:44.003843Z",
     "shell.execute_reply.started": "2023-03-05T13:13:43.992652Z"
    }
   },
   "source": [
    "'''\n",
    "def model_eval(classifier, X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    You pass a defined classifier Object with the desirable hyper parameters. The function then takes the classifier\n",
    "    and fits it to the training data and targets. It then calculates the predictions on the test set. Using the \n",
    "    predictions, it calculates the AUPRC score and plots the ROC curve. It also plots a confusion matrix and returns \n",
    "    the Classification Report of the model and the Recall Score. Finally, it will also calculate the Repeated \n",
    "    Stratified K Fold Cross Validation score of the model.\n",
    "    \n",
    "    Let's get started!\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Fitting the model on training data\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Making predictions on test data\n",
    "    test_preds = classifier.predict(X_test)\n",
    "    \n",
    "    # Calculating AUPRC score for the model on the test data\n",
    "    auprc_score = roc_auc_score(y_test, test_preds)\n",
    "    \n",
    "    # Calculate Recall Score\n",
    "    recall_score = recall_score(y_test, test_preds)\n",
    "    \n",
    "    # Calculate Repeated Stratified K Fold Cross Validation score of the model on \n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "    cross_val_score = cross_val_score(classifier, X_train, y_train, cv=cv, scoring='roc_auc').mean()\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"The AUPRC score is:- \", auprc_score)\n",
    "    print(\"The Recall score is:- \", recall_score)\n",
    "    print(\"The Cross Validation Score is:- \", cross_val_score)\n",
    "    \n",
    "        \n",
    "    # Plot ROC Curve\n",
    "    plot_ROC_Curve(classifier, X_test, y_test)\n",
    "        \n",
    "    # Plot Confusion Matrix\n",
    "    plot_confusion_matrix(y_test, train_preds)\n",
    "    \n",
    "    print(classification_report(y_test,classifier.predict(x_test)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T15:14:47.959806Z",
     "iopub.status.busy": "2023-04-03T15:14:47.959258Z",
     "iopub.status.idle": "2023-04-03T15:14:47.971628Z",
     "shell.execute_reply": "2023-04-03T15:14:47.969133Z",
     "shell.execute_reply.started": "2023-04-03T15:14:47.959763Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_eval(classifier, X_train, y_train, X_test, y_test):    \n",
    "    '''\n",
    "    You pass a defined classifier Object with the desirable hyper parameters. The function then takes the classifier\n",
    "    and fits it to the training data and targets. It then calculates the predictions on the test set. Using the \n",
    "    predictions, it calculates the AUPRC score and plots the ROC curve. It also plots a confusion matrix and returns \n",
    "    the Classification Report of the model and the Recall Score. Finally, it will also calculate the Repeated \n",
    "    Stratified K Fold Cross Validation score of the model.\n",
    "    \n",
    "    Let's get started!\n",
    "    '''\n",
    "    \n",
    "    # Fitting the model on training data\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Making predictions on test data\n",
    "    test_preds = classifier.predict(X_test)\n",
    "\n",
    "    # Calculate Repeated Stratified K Fold Cross Validation score of the model on \n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "    cross_val = cross_val_score(classifier, X_train, y_train, cv=cv, scoring='roc_auc').mean()\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"The AUPRC score is:- \", '{0:.2%}'.format(roc_auc_score(y_test, test_preds)))\n",
    "    print(\"The Recall score is:- \", '{0:.2%}'.format(recall_score(y_test, test_preds)))\n",
    "    print(\"The Cross Validation Score is:- \", '{0:.2%}'.format(cross_val))\n",
    "    \n",
    "        \n",
    "    # Plot ROC Curve\n",
    "    plot_ROC_Curve(classifier, X_test, y_test)\n",
    "        \n",
    "    # Plot Confusion Matrix\n",
    "    plot_confusion_matrix(y_test, test_preds)\n",
    "    \n",
    "    print(classification_report(y_test,test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T15:14:49.717217Z",
     "iopub.status.busy": "2023-04-03T15:14:49.716733Z",
     "iopub.status.idle": "2023-04-03T15:14:49.725848Z",
     "shell.execute_reply": "2023-04-03T15:14:49.724392Z",
     "shell.execute_reply.started": "2023-04-03T15:14:49.717178Z"
    }
   },
   "outputs": [],
   "source": [
    "### This function will be used to just check the model performance while tuning hyperparameters only. Final evaluation\n",
    "### of the model will be done by the model_eval() function\n",
    "def basic_model_eval(classifier, X_train, y_train, X_test, y_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    test_preds = classifier.predict(X_test)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "    cross_val = cross_val_score(classifier, X_train, y_train, cv=cv, scoring='roc_auc').mean()\n",
    "    print(\"The AUPRC score is:- \", '{0:.2%}'.format(roc_auc_score(y_test, test_preds)))\n",
    "    print(\"The Recall score is:- \", '{0:.2%}'.format(recall_score(y_test, test_preds)))\n",
    "    print(\"The Cross Validation Score is:- \", '{0:.2%}'.format(cross_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Now, we are ready to test different kinds of models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h4>1) LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_lr = LogisticRegression(random_state = 0,C=10,penalty= 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval(classifier_lr, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try different values of C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [0.5, 1, 5, 15, 20]:\n",
    "    print(f\"For C = {c}, the model evaluation is as follows:-\")\n",
    "    basic_model_eval(LogisticRegression(random_state = 0,C=c,penalty= 'l2'), X_train, y_train, X_test, y_test)\n",
    "    print('\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So C being greater than 10 isn't giving any significant benefits. We'll keep C = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h4>2) Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "for md in [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]:\n",
    "    print(f\"For max_depth = {md}, the model evaluation is as follows:-\")\n",
    "    basic_model_eval(DecisionTreeClassifier(random_state = 42,max_depth = md,min_samples_leaf = 1),\n",
    "               X_train, y_train, X_test, y_test)\n",
    "    print('\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T11:02:56.396044Z",
     "iopub.status.busy": "2023-03-05T11:02:56.394999Z",
     "iopub.status.idle": "2023-03-05T11:02:56.403974Z",
     "shell.execute_reply": "2023-03-05T11:02:56.402851Z",
     "shell.execute_reply.started": "2023-03-05T11:02:56.395992Z"
    }
   },
   "source": [
    "Observing that the change in recall score and AUPRC score becomes negligible after max_depth=9, we choose max_depth=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_dt = DecisionTreeClassifier(random_state = 42,max_depth = 9,min_samples_leaf = 1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4> 4] Random Forest Classifier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "for n_est in [10, 50, 100, 200, 400, 800]:\n",
    "    print(f\"For n_estimators = {n_est}, the model evaluation is as follows:-\")\n",
    "    basic_model_eval(RandomForestClassifier(n_estimators=n_est, max_depth = 4,random_state = 42),\n",
    "               X_train, y_train, X_test, y_test)\n",
    "    print('\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest AUPRC and Recall Score is for n_estimators=10, so we fix n_estimators=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "for md in [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]:\n",
    "    print(f\"For max_depth = {md}, the model evaluation is as follows:-\")\n",
    "    basic_model_eval(RandomForestClassifier(n_estimators=10, max_depth = md,random_state = 42),\n",
    "               X_train, y_train, X_test, y_test)\n",
    "    print('\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll choose max_depth=11 for our final RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_rf = RandomForestClassifier(random_state=42, n_estimators=10, max_depth=11)\n",
    "model_eval(classifier_rf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4> 4) K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T15:15:03.027289Z",
     "iopub.status.busy": "2023-04-03T15:15:03.026869Z",
     "iopub.status.idle": "2023-04-03T15:15:22.982056Z",
     "shell.execute_reply": "2023-04-03T15:15:22.980512Z",
     "shell.execute_reply.started": "2023-04-03T15:15:03.027254Z"
    }
   },
   "outputs": [],
   "source": [
    "for k in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]:\n",
    "    print(f\"For n_neighbors = {k}, the model evaluation is as follows:-\")\n",
    "    basic_model_eval(KNeighborsClassifier(n_neighbors = k),\n",
    "               X_train, y_train, X_test, y_test)\n",
    "    print('\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select n_neighbors=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in [1, 2, 3, 4, 5, 6]:\n",
    "    print(f\"For p = {l}, the model evaluation is as follows:-\")\n",
    "    basic_model_eval(KNeighborsClassifier(n_neighbors = 3, p = l),\n",
    "               X_train, y_train, X_test, y_test)\n",
    "    print('\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select p = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't think leaf_size is being used by the model at all, so changing leaf size won't really matter anyways\n",
    "# But let's just confirm it once by running the following iteration.\n",
    "for leaf in range(1,7):\n",
    "    print(f\"For leaf_size = {leaf}, the model evaluation is as follows:-\")\n",
    "    basic_model_eval(KNeighborsClassifier(n_neighbors = 3, p = l, leaf_size=leaf),\n",
    "               X_train, y_train, X_test, y_test)\n",
    "    print('\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So leaf doesn't play any major role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T15:15:41.421269Z",
     "iopub.status.busy": "2023-04-03T15:15:41.418912Z",
     "iopub.status.idle": "2023-04-03T15:15:43.346276Z",
     "shell.execute_reply": "2023-04-03T15:15:43.344369Z",
     "shell.execute_reply.started": "2023-04-03T15:15:41.421197Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier_knn = KNeighborsClassifier(n_neighbors = 3, p = 1)\n",
    "model_eval(classifier_knn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T14:33:16.013573Z",
     "iopub.status.busy": "2023-03-05T14:33:16.013134Z",
     "iopub.status.idle": "2023-03-05T14:33:16.020383Z",
     "shell.execute_reply": "2023-03-05T14:33:16.019047Z",
     "shell.execute_reply.started": "2023-03-05T14:33:16.013534Z"
    }
   },
   "source": [
    "- Recall Score: 98.20%\n",
    "- F1 Score (for fraud): 96%\n",
    "- AUPRC Score: 97.67%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T15:17:51.246489Z",
     "iopub.status.busy": "2023-04-03T15:17:51.246030Z",
     "iopub.status.idle": "2023-04-03T15:17:51.253497Z",
     "shell.execute_reply": "2023-04-03T15:17:51.252135Z",
     "shell.execute_reply.started": "2023-04-03T15:17:51.246451Z"
    }
   },
   "outputs": [],
   "source": [
    "final_model = classifier_knn\n",
    "import pickle\n",
    "pickle.dump(final_model, open('final_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So\n",
    "our best model is KNN with 3 neighbors and p = 1. I now want to take this model and check its performance on different kinds of oversampling and undersampling sampling strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_model_on_new_sampling_strategies(oversample_strategy, undersample_strategy, df=df1):\n",
    "    \n",
    "    ### Data Sampling\n",
    "    undersampler = RandomUnderSampler(sampling_strategy=undersample_strategy, random_state=42)\n",
    "    oversampler = SMOTE(sampling_strategy=oversample_strategy, random_state=42)\n",
    "    X1 = df.iloc[:,:9].values  \n",
    "    y1 = df.iloc[:,9].values\n",
    "    pipe = Pipeline([('undersampling', undersampler), ('oversampling', oversampler)])\n",
    "    X1, y1 = pipe.fit_resample(X1, y1)\n",
    "    \n",
    "    ### Making training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size = 0.20, random_state = 42)\n",
    "    \n",
    "    ### Initializing KNN Classifier Object\n",
    "    curr_classifier = KNeighborsClassifier(n_neighbors = 3, p = l)\n",
    "    \n",
    "    ### Basic Evaluation of the model\n",
    "    basic_model_eval(curr_classifier, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try:-\n",
    "- undersample_strategy = 0.05\n",
    "- Oversample_strategy = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_eval_model_on_new_sampling_strategies(0.75, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens when you put oversample_strategy=1 ? xD\n",
    "get_eval_model_on_new_sampling_strategies(1, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample = 1\n",
    "# Undersample = 0.01\n",
    "get_eval_model_on_new_sampling_strategies(1, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Is this causing overfitting?????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
